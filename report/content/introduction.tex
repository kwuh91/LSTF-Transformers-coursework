\section*{ВВЕДЕНИЕ}

% add to toc
\phantomsection
\addcontentsline{toc}{section}{ВВЕДЕНИЕ}

% ------------------------------------CONTENT--------------------------------------

Прогнозирование временных рядов является фундаментальной задачей во множестве 
прикладных областей, включая экономику, инженерию и естественные науки. 
Традиционные статистические методы, такие как ARIMA, заложили основу для 
анализа и предсказания последовательных данных, однако их возможности ограничены 
при работе со сложными нелинейными зависимостями.

Развитие глубокого обучения открыло новые горизонты в моделировании 
временных рядов. Рекуррентные нейронные сети (RNN), в частности их 
усовершенствованные варианты, такие как LSTM и GRU, продемонстрировали 
значительные успехи в захвате временных зависимостей. Тем не менее, их 
последовательная природа накладывает ограничения на распараллеливание 
вычислений и усложняет эффективное запоминание долгосрочных паттернов 
из-за проблемы затухающего градиента.

Революционным шагом в обработке последовательностей стала архитектура 
Трансформер, основанная исключительно на механизме внимания. Отказавшись 
от рекуррентности, она позволила эффективно моделировать глобальные 
зависимости в данных и значительно ускорить процесс обучения. Несмотря 
на успех, стандартный Трансформер сталкивается с проблемами квадратичной 
вычислительной сложности и высокого потребления памяти, что делает его 
применение для задач долгосрочного прогнозирования временных рядов (Long 
Sequence Time-Series Forecasting, LSTF) затруднительным.

Данная работа посвящена исследованию и решению этих проблем. Целью является 
разработка и апробация гибридной архитектуры, синтезирующей передовые идеи из 
современных моделей, таких как Informer, Performer и Autoformer. В работе 
предлагается модифицированная модель, которая объединяет в себе эффективность 
сверточных слоев для извлечения локальных признаков, линейную сложность 
механизма внимания для учета глобальных зависимостей и явный механизм 
декомпозиции для разделения трендовых и сезонных компонент.

В теоретической части работы последовательно рассматриваются основы анализа 
временных рядов, фундаментальные концепции глубокого обучения, архитектуры 
рекуррентных сетей и Трансформеров. Практическая часть посвящена описанию 
предложенной модели, постановке и проведению вычислительных экспериментов, 
а также анализу полученных результатов в сравнении с базовыми моделями.

% ------------------------------------CONTENT--------------------------------------

% remove centering from sections
\titleformat{\section}
  {\normalfont\large\bfseries}{\thesection}{1em}{}
