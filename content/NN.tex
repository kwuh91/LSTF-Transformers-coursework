% split code (latex) parts into different files

% enhance listings

% "Deep Learning for Time Series Forecasting" by Jason Brownlee

% RNNs (Recurrent Neural Networks) (можно чуть чуть написать и сказать, что затронем 
% подробнее в следующей главе)

% LSTM (Long Short-Term Memory) (может пока не трогать, тк это модификация RNN)

% GRU (может пока не трогать, тк это модификация RNN)

% -------------

% topological intuition behind NN
% talk about backpropagation 
% universal approximation theorem (from Goodfellow)
% Manifold learning
% intuition behind thinking in n dimensions
% sigmoid/relu/softmax e.t.c. discussion for which is better
% parallel to neurobilogy
% architecture definition, main terms
% feed forward/not feed forward
% talk about gradient descent (stohastic, adam?)
% bayessian statistics? how is it different from classic 
% the idea of deriving cost functions from maximum likelihood
% maximum likelihood
% no free lunch theorem
% Regularization
% SVM and kernel trick
% cross entropy and Kullback–Leibler divergence

% --------------

% https://chatgpt.com/c/6817eeff-5420-8010-b35d-3c35fed4bdcf
% https://aistudio.google.com/prompts/1akCvM2Z46N9sApnbcqEbhtnS8eMy7HLz

% Part 1: Setting the Stage - What are we trying to do?
%     Introduction to Machine Learning & Supervised Learning

%     Intuition behind Thinking in n Dimensions

%     maybe drop:
%     (SVM & the kernel trick (how it bends space (later will be compared to nonlinearity in activation functions)))

%     What Is a Neural Network?
%     - Parallel to neurobiology
%     - Architecture definitions & main terms
%     - Feed‑forward vs. recurrent    

% Part 2: How Neural Networks "Compute"
%     How NNs “Fire”
%     - Activation functions(Sigmoid/ReLU/Softmax etc.):
%     (show how each nonlinearity “folds” space)
        
%     Geometric & Topological Intuition
%     - Manifold learning (quick review, mainly for intuition)
%     - topological intuition behind NN

% Part 3: How Neural Networks Learn
%     Cost functions (MSE, cross-entropy)

%     Probabilistic loss
%     - maximum likelihood 
%     - Deriving Cost Functions from Maximum Likelihood
%     (Cross‑entropy & Kullback–Leibler divergence (note: cross‑entropy ↔ KL divergence & MLE in one bullet))

%     Gradient descent mechanism (closed optimization, convex, e.t.c.)
%     Backpropagation
%     Optimization landscapes: local minima vs. saddle points (intuition).
%     Gradient Descent Variants (Stochastic, Mini-batch, Adam)

% Part 4: Theoretical & Practical Considerations
%     Universal Approximation Theorem
%     Overfitting and Underfitting
%     Regularization
%     Training, Validation, and Test Sets (hyperparameter tuning)
%     No Free Lunch Theorem

% Part 5: Bridging to RNNs
%     Limitations of Feed-Forward Networks for Sequences

% --------------

% Dimensionality reduction and visualisation of high dimensional data (https://colah.github.io/posts/2014-10-Visualizing-MNIST/)
% t-SNE

% \section{Рекуррентные нейронные сети}
\section{Глубокие сети}

Глубокие сети прямого распространения, которые называют также нейронными
сетями прямого распространения, или многослойными перцептронами (МСП), -
самые типичные примеры моделей глубокого обучения. Цель сети прямого расп­рост­ранения 
- аппроксимировать некоторую функцию $f^*$. Например, в случае классификатора 
$y = f^*(\bm{x})$ отображает вход $\bm{x}$ в категорию $y$. Сеть прямого распространения
определяет отображение $y = f(\bm{x}; \bm{\theta})$ и путем обучения находит 
значения параметров $\bm{\theta}$, дающие наилучшую аппроксимацию.

%todo: why do wee need them from predicting time series?

\subsection{Что такое нейронная сеть?}

В данной главе кратко вводятся основные понятия глубокого обучения. 
Чтобы понять, как нейронные сети обрабатывают информацию, 
полезно сначала рассмотреть, как мы представляем данные, 
с которыми они работают. Часто эти данные существуют в многомерных пространствах, 
поэтому мы сначала сформулируем методы мышления в этих пространствах.
Затем рассмотрим модель перцептрона и закончим данную главу ознакомлением с 
архитектурой многослойного перцептрона (MLP), 
определив все, сопутствующие ему, основные термины.

Предполагается, что читатель уже знаком с основами классического машинного обучения, 
поэтому мы не будем подробно останавливаться на соответствующих понятиях.

\subsubsection{Интуиция мышления в высоко-мерных пространствах}

В процессе эволюции люди научились рассуждать в двух и трех измерениях. 
Приложив достаточно усилий, мы можем мыслить и в четырех измерениях. 
Машинное обучение часто требует от нас работы с тысячами измерений - 
или десятками тысяч, или миллионами. Даже очень простые вещи становится 
трудно понять, когда вы делаете их в очень большом количестве измерений.

Поэтому важно иметь в запасе методы для работы с такими данными. 
Люди, которые научились хорошо мыслить в высоких измерениях часто 
распологают, своего рода, ментальной библиотекой, содержащей множество 
различных техник. Возможно, эти техники не выделяются простотой, 
к которой мы привыкли при визуализации трех измерений, но, 
собрав библиотеку таких техник, вы сможете довольно хорошо научиться 
мыслить в высоких измерениях.

Рассмотрим несколько таких техник \cite{ndim_thinking}:

\begin{quoting}
    \itshape
    “Можно рассматривать высокоразмерное векторное пространство как 
    пространство состояний для системы со многими степенями свободы. 
    Например, мегапиксельное изображение - это точка в миллионном 
    векторном пространстве; изменяя изображение, можно исследовать 
    это пространство, и различные подмножества этого пространства 
    соответствуют различным классам изображений.

    Аналогичным образом можно интерпретировать звуковые волны, 
    коробку с газами, экосистему, совокупность избирателей, поток 
    цифровых данных, испытания случайных величин, результаты 
    статистического исследования, вероятностную стратегию в игре 
    двух игроков и многие другие конкретные объекты как состояния 
    в высокоразмерном векторном пространстве, а различные базовые 
    понятия, такие как выпуклость, расстояние, линейность, смена 
    переменных, ортогональность или внутреннее произведение, могут 
    иметь вполне естественные значения в некоторых из этих моделей 
    (хотя и не во всех).“
\end{quoting}

\begin{quoting}
    \itshape
    “Если вы пытаетесь представить себе некое 4D явление $P$, 
    сначала подумайте о соответствующем 3D явлении $P'$, 
    а затем представьте себя в роли 2D существа, которое 
    пытается представить себе $P'$. Преимущество в том, что, в отличие 
    от случая 4D vs. 3D, вы сами можете легко переключаться между 3D 
    и 2D перспективами и, следовательно, можете получить представление 
    о том, какая именно информация теряется, когда вы опускаете измерение. 
    (Можно назвать это «трюком Флатландии» ("Flatland trick"), в честь самого 
    известного литературного произведения, опирающегося на данную идею).“
\end{quoting}

Нейронные сети оперируют именно с такими многомерными представлениями данных, 
преобразуя их для решения поставленных задач.

\subsubsection{Нейронная сеть}

Нейронные сети, как можно догадаться из названия, были вдохновлены работой человеческого 
мозга. Идея использовать несколько слоев векторных представлений пришла из нейробиологии. 
Выбор функций, используемых для расчета этих представлений был также навеян 
экспериментально полученными фактами о функциях, вычисляемых биологическими нейронами. 
Современные исследования в области нейронных сетей, однако, руководствуются 
многими математическими и инженерными дисциплинами, и у них нет цели идеально 
смоделировать работу мозга. О сетях прямого распространения лучше думать 
не как о моделях функционирования мозга, а как о 
механизмах для аппроксимации функций, спроектированных с целью достижения 
статистического обобщения, периодически вдохновляемых нашими знаниями о работе 
мозга.

\paragraph{Перцептрон}

Нейронная сеть (neural network) строится из простейших элементов - искусственных 
нейронов. Одной из первых моделей такого нейрона был перцептрон, 
предложенный Фрэнком Розенблаттом в 1958 году \cite{Rosenblatt_perceptron}. Несмотря на то, что в 
современных архитектурах чаще используют сигмоидальные и ReLU-нейроны, 
понимание перцептрона важно для осознания эволюции подходов к обучению 
и архитектуре сетей.

Так как работает модель перцептрона? Перцептрон принимает на вход несколько бинарных значений: 
$x_1, x_2, ..., x_n $ и возвращает единственное бинарное значение:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth, keepaspectratio]{perceptron}
    \caption{Модель перцептрона.}
    \label{fig:perceptron}
\end{figure}

Розенблатт предложил простую идею для расчета выходного значения. Он ввел понятие 
весов $w_1, w_2, ..., w_n$, действительных значений, отражающих важность каждого из, 
соответствующих входов. Выходное значение нейрона определяется из правила, превышает 
ли взвешенная сумма входов некоторое наперед заданное значение, называемое порогом 
(threshold):

\begin{equation*}
    \text{output} = \begin{cases}
        0 \quad \text{if} \quad \sum_j w_j x_j \leq \text{threshold} \\
        1 \quad \text{if} \quad \sum_j w_j x_j > \text{threshold} 
    \end{cases}
\end{equation*}

Однако, в машинном обучении чаще используют упрощенную версию данной записи. 
Перепишем $\sum_j w_j x_j$ в виде скалярного произведения, \hspace{20pt}
$\bm{w} \cdot \bm{x} \equiv \sum_j w_j x_j$, 
а порог заменим смещением (bias), $b \equiv -\text{threshold}$. Тогда наша запись примет вид:

\begin{equation*}
    \text{output} = \begin{cases}
        0 \quad \text{if} \quad \bm{w} \cdot \bm{x} + b \leq 0 \\
        1 \quad \text{if} \quad \bm{w} \cdot \bm{x} + b > 0 
    \end{cases}
\end{equation*}

Одним из примеров применения перцептрона может послужить вычисление логических функций.
Так, например, рассмотрим перцептрон, у которого всего два входа, $x_1, x_2 \in \left\{ 0, 1 \right\}$. 
И вручную примем $w_1 = w_2 = -2, \quad b = 3$. Тогда наш перцептрон примет вид:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth, keepaspectratio]{perceptron2}
    \caption{Пример перцептрона с весами $\bm{w} = \left[ -2 \hspace{3pt} -2 \right]^T$ и 
    смещением $b = 3$.}
    \label{fig:perceptron2}
\end{figure}

При $\bm{x} = \left[ 0 \hspace{3pt} 0 \right]^T$, получим $1$, т.к. 
$\bm{w} \cdot \bm{x} + b = (-2) \cdot 0 + (-2) \cdot 0 + 3 = 3 > 0$.
Построим таблицу всех значений:

\begin{minipage}{0.4\textwidth}
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{ccc}
        $x_1$ & $x_2$ & $f$ \\
        \midrule
        0 & 0 & 1 \\
        0 & 1 & 1 \\
        1 & 0 & 1 \\
        1 & 1 & 0 \\
    \end{tabular}
    \captionof{table}{Значения, которые принимает перцептрон (\ref{fig:perceptron2}) 
    при различных значениях $x_1, x_2 \in \left\{ 0, 1 \right\}$.}
    \label{tab:perceptron-values}
\end{minipage}
\hspace{30pt}
\begin{minipage}{0.4\textwidth}
    \includegraphics[width=\linewidth]{NAND}
    \captionof{figure}{Штрих Шеффера (NAND gate).}
    \label{fig:NAND}
\end{minipage}\\

Таким образом, наш перцептрон реализует Штрих Шеффера (NAND gate). 
Исходя из этого примера видно, что мы можем использовать перцептроны для 
расчета простых логических функций. Вообще говоря, мы можем рассчитать любую логическую 
(и не только, см. {\color{red} главу...}) функцию, 
используя сеть из перцептронов, называемаю нейронной сетью.

\paragraph{Архитектура нейронной сети}

Нейронная сеть состоит из композиции нейронов (т.е. когда в качестве входов для 
нейронов используются выходы других нейронов), например:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth, keepaspectratio]{NN_example1}
    \caption{Архитектура простой нейронной сети.}
    \label{fig:NN1}
\end{figure}

Самый левый слой называется \textit{входным слоем (input layer)}, а нейроны в нем 
называются \textit{входными нейронами (input neurons)}. Самый правый, или же 
\textit{выходной слой (output layer)} содержит в себе 
\textit{выходные нейроны (output neurons)}. Слои между ними называются 
\textit{скрытыми (hidden layers)}. Количество скрытых слоев определяет 
\textit{глубину (depth)} нейронной сети, а размерность скрытых слоев 
определяет \textit{ширину (width)} модели.

Подобные сети называют \textit{многослойными перцептронами (MLPs)}. (Исторически пошло, 
что иногда их так называют даже когда они состоят не из перцептронов). 

\paragraph{feedforward vs recurrent}

До сих пор мы обсуждали нейронные сети, в которых выход из одного слоя используется как 
вход для следующего. Подобные сети называются \textit{нейронными сетями прямого распространения 
(feedforward neural networks)}. Это значит, что у нас нет циклов в сети - информация всегда 
поступает вперед и никогда не возвращается назад.

Однако существуют и другие модели искусственных нейронных сетей, 
в которых возможны циклы обратной связи. Подобные модели называются 
\textit{рекуррентными нейронными сетями (recurrent neural networks)} 
(см. {\color{red} главу...}). 
Идея этих моделей заключается в 
том, что нейроны работают в течение некоторого ограниченного периода 
времени, а затем затихают. Это возбуждение может стимулировать другие 
нейроны, которые через некоторое время также возбуждаются на ограниченное 
время. Это заставляет еще большее количество нейронов срабатывать, и 
так со временем мы получаем каскад нейронов, которые срабатывают. Циклы 
в такой модели не вызывают проблем, так как выход нейрона влияет на его 
вход только через некоторое время, а не мгновенно \cite{NN_Nielsen}.

\subsection{Как нейронные сети «вычисляют»?}

\textit{Функции активации} в нейронной сети задают правило преобразования 
взвешенной суммы входа в выход. Простейший пример функции активации мы уже 
рассмотрели на примере перцептрона, однако в силу своей простоты, он не очень 
эффективен. 

Выбор функции активации оказывает огромное виляние на возможности и производительность 
нейронной сети, и различные функции активации могут быть использованы в раличных частях модели.

Как правило, всем скрытым слоям назначают одну и ту же функцию активации, 
а функция активации выходного слоя, как правило, отличается и подбирается в 
зависимости от типа решаемой задачи.

Функции активации также обычно дифференцируемы, то есть производная первого порядка 
может быть вычислена для заданного входного значения. Это необходимо, учитывая, что 
нейронные сети обычно обучаются с помощью алгоритма обратного распространения ошибки 
(см. главу {\color{red} todo}), 
который требует производной ошибки прогнозирования для обновления весов модели.

Существует множество различных функций активациии, но на практике используется не 
так много. Вообще говоря, многие дифференцируемые функции показывают отличные результаты. 
Есть целый ряд неопубликованных функций активации, которые ведут
себя ничуть не хуже популярных, однако в ходе исследований обычно 
обнаруживается, что результаты, полученные при отходе от стандартной практики, 
вполне сопоставимы. Это означает, что новые типы скрытых блоков
обычно публикуются только в случае, когда улучшение весомо и очевидно. Скрытые
блоки, работающие примерно так же, как известные, - дело настолько обычное, что
рассматривать их неинтересно.

\subsubsection{Функции активации}

До сих пор, мы подбирали параметры вручную. Однако, у нас возникли бы серьезные 
проблемы, если бы мы захотели подобрать параметры к, например, следующей нейронной сети:

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth, keepaspectratio]{NN_example3}
    \caption{Архитектура нейронной сети.}
    \label{fig:NN3}
\end{figure}

Которая, вообще говоря, считается относительно небольшой по современным меркам 
(ходят слухи, что модель GPT-4 насчитывает $\sim 1.8$ триллионов параметров в 
120 слоях \cite{gpt4_architecture}).

Однако ситуация лучше, чем кажется на первый взгляд. 
Проектирование и обучение нейронной сети не сильно отличается от обучения 
любой другой модели машинного обучения с помощью градиентного спуска. 

Таким образом, мы возвращаеся к проблеме перцептронов с жёсткой (ступенчатой) 
функцией активации:
\begin{equation*}
    \text{output} = \begin{cases}
        0 \quad \text{if} \quad \bm{w} \cdot \bm{x} + b \leq 0 \\
        1 \quad \text{if} \quad \bm{w} \cdot \bm{x} + b > 0 
    \end{cases}
\end{equation*}

Хотя такая модель достаточно проста, её основное ограничение в том, 
что функция активации не является дифференцируемой в точке разрыва, 
а её производная равна нулю везде, где она определена. 
Из-за этого градиентный спуск применять невозможно: градиент отсутствует или 
обращается в ноль, и веса не обновляются.

\paragraph{Сигмоидальные блоки}

На помощь приходит новый вид искусственных нейронов, называемый 
\textit{сигмоидальным (sigmoid neuron)} (далее будем называть просто сигмоидом). 
Основное отличие от перцептрона заключается в том, что
сигмоид может вернуть любое значение из интервала от 0 до 1, 
задаваемое гладкой, непрерывно дифференцируемой функцией $\sigma$, 
называемой сигмоидальной функцией:
\begin{equation*}
    \sigma(z) \defeq \cfrac{1}{1 + e^{-z}}
\end{equation*}

Таким образом функция активации принимает вид:
\begin{equation*}
    \text{output} = \sigma(\bm{wx} + b) = \cfrac{1}{1 + e^{-\bm{wx} - b}}
\end{equation*}

Если мы посмотрим на графики функций активации перцептрона и сигмоида, то 
заметим, что сигмоидальная функция это просто сглаженная версия ступенчатой 
(Вообще говоря, при $\bm{wx + b = 0}$ перцептрон возвращает 0, а ступенчатая 
функция 1. Так что строго говоря ступенчатую функцию следовало бы изменить в 
этой одной точке, чтобы ее можно было называть функцией активации перцептрона, но 
суть понятна).

\begin{minipage}{0.4\textwidth}
    \includegraphics[width=\linewidth]{step}
    \captionof{figure}{График ступенчатой функции.}
    \label{fig:step}
\end{minipage}
\hspace{30pt}
\begin{minipage}{0.4\textwidth}
    \includegraphics[width=\linewidth]{sigma}
    \captionof{figure}{График сигмоидальной функции.}
    \label{fig:sigma}
\end{minipage}\\

Иногда вместо сигмоидальной функции используют гиперболический тангенс\\ 

\begin{minipage}{0.4\textwidth}
    \includegraphics[width=\linewidth]{tanh}
    \captionof{figure}{График гиперболического тангенса.}
    \label{fig:tanh}
\end{minipage}
\hspace{30pt}
\begin{minipage}{0.3\textwidth}
    \begin{equation*}
        \text{tanh}(z) \defeq \cfrac{e^{2z} - 1}{e^{2z} + 1}
    \end{equation*}
\end{minipage}\\

Эти функции активации тесно связаны: $\text{tanh}(z) = 2 \sigma(2z) - 1$.

Однако, сигмоидальные блоки близки к асимптоте в большей части своей области определения -
приближаются к высокому значению, когда $z$ стремится к бесконечности, и к низкому,
когда $z$ стремится к минус бесконечности. Высокой чувствительностью они обладают 
только в окрестности нуля. Из-за насыщения сигмоидальных блоков градиентное
обучение сильно затруднено. Поэтому использование их в качестве скрытых блоков
в сетях прямого распространения ныне не рекомендуется. Применение же в качестве
выходных блоков совместимо с обучением градиентными методами, если функция
стоимости компенсируется насыщением сигмоиды в выходном слое.

Сигмоидальные функции активации все же применяются, но не в сетях прямого
распространения. К рекуррентным сетям, многим вероятностным моделям и некоторым 
автокодировщикам предъявляются дополнительные требования, исключающие
использование кусочно-линейных функций активации и делающие сигмоидальные
блоки более подходящими, несмотря на проблемы насыщения.

\paragraph{Блоки линейной ректификации}

В качестве функции активации по умолчанию для большинства нейронных сетей прямого 
распространения рекомендуется ректифицированная линейная функция активации (ReLU):

\begin{minipage}{0.45\textwidth}
    \includegraphics[width=\linewidth]{ReLU}
    \captionof{figure}{График ректифицированной линейной функции.}
    \label{fig:ReLU}
\end{minipage}
\hspace{30pt}
\begin{minipage}{0.2\textwidth}
    \begin{align*}
        \text{ReLU}(z) &= z^{+} \\
        &= \text{max}(0, z) \\
        &= \cfrac{z + |z|}{2} \\[0.5em]
        &= \begin{cases}
            z \quad \text{if} \quad z > 0, \\
            0 \quad \text{if} \quad z \leq 0
        \end{cases}
    \end{align*}
\end{minipage}\\

Применение ее к выходу линейного преобразования дает нелинейное преобразование. 
Функция, впрочем, очень близка
к линейной - она является кусочно-линейной с двумя линейными участками. 
Поскольку блоки линейной ректификации почти линейны, сохраняются
многие свойства, благодаря которым линейные модели легко поддаются
оптимизации градиентными методами. Сохраняются также свойства, обес­печивающие 
хорошую обобщаемость линейных моделей. Общий принцип
информатики - строить сложные системы из минимальных компонентов.
От памяти машины Тьюринга требуется только способность хранить нуль
и единицу, а универсальный аппроксиматор можно построить из ректифи-
цированных линейных функций \cite{Goodfellow-et-al-2016}.

\paragraph{Нелинейность}

После того как мы познакомились с различными функциями активации, 
возникает естественный вопрос: зачем вообще нужны эти нелинейные функции активации? 
Почему бы не использовать простые линейные функции? 
Ведь их так легко оптимизировать методом градиентного спуска. 
К сожалению, дело в том, что композиция любых линейных преобразований остаётся линейной 
функцией входа, а значит и вся сеть прямого распространения остается линейной 
функцией входа.

Пусть у нас есть две кривые линии на плоскости и задача нейронной сети заключается в том, 
чтобы классифицировать к которой из двух кривых принадлежит та или иная точка. В случае 
линейной модели, мы бы не добились особого успеха, тк наши кривые линейно неразделимы:\\

\begin{minipage}{0.35\textwidth}
    \includegraphics[width=\linewidth]{colah1}
    \captionof{figure}{}
    \label{fig:colah1}
\end{minipage}
\hspace{80pt}
\begin{minipage}{0.35\textwidth}
    \includegraphics[width=\linewidth]{colah2}
    \captionof{figure}{}
    \label{fig:colah2}
\end{minipage}\\

Однако, если перед классификацией, мы преобразуем наши данные 
(в данном случае, с применением сигмоидальной функции), 
то получим их \textit{представление (representation)} в 
пространстве, в котором их уже легче классифицировать \cite{colah}:

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth, keepaspectratio]{colah3}
    \caption{Иллюстрация того, как нелинейный слой «разворачивает» 
    данные в новом пространстве признаков, делая их линейно разделимыми.}
    \label{fig:colah3}
\end{figure}

Таким образом, каждый слой с нелинейной активацией потенциально «перестраивает» или 
«разворачивает» пространство признаков, делая сложные зависимости более явными для 
последующих слоев или для финального классификатора.

\subsubsection{Многообразия и топология {\color{red} todo}}

% leave for later

% manifolds from goodfellow, topology from colah

% Placement: This could fit well after the "Нелинейность" paragraph and the 
% Colah visualization.

% Content (Keep it Intuitive):

%     "Данные, с которыми мы работаем (например, изображения, звуки), 
%     хоть и представлены в пространствах высокой размерности, 
%     часто лежат на структурах меньшей размерности, называемых 
%     многообразиями (manifolds)." (Think of a rolled-up sheet of 
%     paper in 3D space – the paper itself is 2D).

%     "Задача нейронной сети, с этой точки зрения, – научиться 'разворачивать' 
%     эти сложные многообразия или преобразовывать их так, чтобы интересующие 
%     нас классы или закономерности стали легко отделимы (например, линейно отделимы)."

%     "Нелинейные функции активации и многослойная архитектура как раз и 
%     позволяют сети выполнять такие сложные топологические преобразования 
%     пространства признаков."

%     Avoid deep math. Focus on the idea of "simplifying the data's geometry."

\subsection{Как нейронные сети обучаются?}

Теперь, когда мы понимаем устройство нейронной сети, возникает вопрос: 
как подобрать её параметры (веса и смещения) так, чтобы она решала нужную нам задачу? 
Из машинного обучения известно, что данный процесс называется обучением модели и требует 
способа измерить насколько хорошо модель справляется с задачей на имеющихся у нас данных. 
Эту роль выполняет \textit{функция стоимости (или функция потерь)}.

\subsubsection{Функции стоимости}

Большинство современных нейронных сетей обучают с применением метода максимального 
правдоподобия. То есть функция стоимости это просто отрицательное логарифмическое 
правдоподобие, которое можно эквивалентно описать как перекрестную энтропию 
между обучающими данными и распределением модели. Подобная функция стоимости 
задается формулой 
\begin{equation*}
    J(\theta) = - \mathbb{E}_{\bm{x},\bm{y} \sim \hat{p}_{\text{data}}} \text{log} \left[ p_\text{model} (\bm{y} | \bm{x}) \right].
\end{equation*}

Интуитивно, минимизация такой функции стоимости эквивалентна поиску таких параметров 
модели, при которых наблюдаемые нами данные были бы наиболее «вероятны» с точки 
зрения модели.

Конкретная форма функции стоимости меняется от модели к модели в зависимости от выбранной 
формы $\text{log} \left[ p_\text{model} \right]$. Раскрытие этой формулы обычно дает члены, которые не
зависят от параметров модели и могут быть отброшены. Например если принять 
$p_\text{model}(\bm{y} | \bm{x}) = N(\bm{y}; f(\bm{x}; \bm{\theta}), \bm{I})$, то 
мы получим знакомую среднеквадратическую ошибку (MSE):
\begin{equation*}
    J(\theta) = \cfrac{1}{2} \mathbb{E}_{\bm{x},\bm{y} \sim \hat{p}_{\text{data}}} || \bm{y} - f(\bm{x}; \bm{\theta}) ||^2 + \text{const}.
\end{equation*}

с точностью до масштабного коэффициента $\frac{1}{2}$ и члена, не зависящего от 
$\bm{\theta}$. 

Преимущество такого подхода - вывода функции стоимости из оценки максимального 
правдоподобия - в том, что отпадает необходимость проектировать функцию 
стоимости заново для каждой модели. Задание модельного распределения $p(\bm{y} | \bm{x})$ 
автоматически определяет функцию стоимости $\text{log} \left[ p(\bm{y} | \bm{x}) \right]$ 
\cite{Goodfellow-et-al-2016}.

\subsubsection{Метод обратного распространения ошибки}

Метод обратного распространения ошибки (backpropagation, далее backprop) это 
эффективный способ вычисления градиента при обучении глубоких нейронных сетей. 
Вообще говоря это ключевый алгоритм, который сделал обучение глубоких моделей 
вычислительно возможным. Для современных нейронных сетей, в некоторых случаях, 
он позволяет ускорить обучение методом градиентного спуска в 10 миллионов раз, по 
сравнению с наивным подходом (для сравнения, это разница между тем, что модель 
обучается неделю и 200 000 лет). 

Backprop не эксклюзивен для глубокого обучения, этот мощный вычислительный 
инструмент используют и во многих дургих областях, просто под другим названием. 
В общем случае алгоритм носит название «Reverse mode automatic differentiation».

\paragraph{Предпосылка}

В основе алогритма лежит правило дифференцирования сложной функции 
(Chain Rule of Calculus), которое мы последовательно используем для 
расчета производных функций, сформированных композицией других функций, чьи 
производные мы уже знаем.

С использованием backprop, обучение нейронной сети происходит в два этапа:

\textbf{Прямое распространение (Forward Propagation):} 
Во время прямого распространения, NN пытается
угадать лучший, возможный на текущий момент, результат. 
Для этого она пропускает входные данные через 
каждый свой слой.

\textbf{Обратное распространение (Backward Propagation):} 
Во время обратного распространения, NN
подстраивает свои параметры, пропорционально ошибке, полученной из попытки
угадывания. Она это делает, перемещаясь обратно от результата, собирая
производные ошибки по отношению к параметрам функции (градиенты), и
оптимизируя параметры с помощью градиентного спуска.

\paragraph{Вычислительный граф}

Концептуально, математические выражения удобно рассматривать в виде 
вычислительных графов. Допустим у нас есть некоторое выражение $f$, 
составленное из переменных $a, b, c$:
\begin{equation*}
    f = 3a + b^2 - c^a
\end{equation*}

Введем для удобства еще две переменные $d, e$:
\begin{gather*}
    d = 3 \cdot a + b^2 \\
    e = c^a \\
    f = d - e
\end{gather*}

Тогда вычистельный граф данного выражения можно представить в виде:
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth, keepaspectratio]{backprop_graph_forward}
    \caption{Вычислительный граф выражения $f = 3a + b^2 - c^a$, разбитого на две 
    дополнительные части: $e = c^a$ и $d = 3a + b^2$. $a, b, c$ - переменные.}
    \label{fig:backprop_graph_forward}
\end{figure}

% \begin{tikzpicture}[
%     >=latex,
%     node distance=2cm,
%     thick,                             % make all lines bolder
%     every circle/.style={minimum size=1cm},           % all circles at least 1cm diameter
%     every ellipse/.style={minimum width=3cm, minimum height=1cm}
%   ]
%   % bottom layer: input circles
%   \node[draw,circle] (c) at (0,0) {$c$};
%   \node[draw,circle] (a) at (3,0) {$a$};
%   \node[draw,circle] (b) at (6,0) {$b$};

%   % middle layer: ellipses
%   \node[draw,ellipse] (e) at (1,2) {$e = c^a$};
%   \node[draw,ellipse] (d) at (5,2) {$d = 3a + b^2$};

%   % top layer: ellipse
%   \node[draw,ellipse] (f) at (3,4) {$f = d - e$};

%   % arrows
%   \draw[->] (c) -- (e);
%   \draw[->] (a) -- (e);
%   \draw[->] (a) -- (d);
%   \draw[->] (b) -- (d);
%   \draw[->] (e) -- (f);
%   \draw[->] (d) -- (f);
% \end{tikzpicture}

\newpage
Выбрав определенные значения для $a, b, c$ мы можем вычислить чему будует равно 
наше выражение $f$:
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth, keepaspectratio]{backprop_graph_forward_eval}
    \caption{Вычислительный граф выражения, изображенного на рис. 
    \ref{fig:backprop_graph_forward}, вычисленного при $a=1, b=2, c=5$.}
    \label{fig:backprop_graph_forward_eval}
\end{figure}

Таким образом мы произвели прямой проход по графу (прямое распространение): 
от входных значений к выходному. Достигнув нашей вершины графа, мы 
теперь можем развернуть направление стрелок и пройтись в обратном направлении 
(обратное распространение), считая частные производные. В конечном итоге мы получим 
производную $f$ относительно всех узлов:

\begin{minipage}{0.45\textwidth}
    \includegraphics[width=\linewidth]{backprop_graph_combined_forward}
    \captionof{figure}{Прямой проход вычислительного графа.}
    \label{fig:backprop_graph_combined_forward}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
    \includegraphics[width=\linewidth]{backprop_graph_combined_backward}
    \captionof{figure}{Обратный проход вычислительного графа.}
    \label{fig:backprop_graph_combined_backward}
\end{minipage}\\

Таким образом, всего за два прохода (прямой и обратный), мы можем 
найти производные желаемой функции, относительно всех ее составляющих. 
Если бы мы воспользовались дифференцированием прямого распространения 
(forward-mode differentiation), то получили бы производные всех составляющих 
по одной выбранной переменной (например: 
$\frac{\partial f}{\partial a}, \frac{\partial e}{\partial a}, 
\frac{\partial d}{\partial a}, \frac{\partial a}{\partial a}, 
\frac{\partial b}{\partial a}, \frac{\partial c}{\partial a}$), 
что тоже иногда применимо, но в нашем случаем потребовало бы еще 5ти вызов 
для расчета градиента функции $f$, что звучит как немного, но если 
вспомнить, что в глубоком обучении мы обычно имеем дело с функциями 
миллионов и миллиардов переменных, то выигрыш 1 000 000 000 vs 1 (если не брать в расчет 
прямое распространение) звучит неплохо.

\paragraph{4 фундаментальных уравнения метода обратного распространения ошибки}

До сих пор мы рассматривали логику работы backprop-а на примере функции 
3х переменных. Однако теперь, когда мы интуитивно понимаем как работает метод, 
рассмотрим его с более формальной стороны уже на примере нейронной сети. 

Для начала определим обозначения, которые позволят нам однозначно ссылаться на 
элементы в сети:
\begin{itemize}
    \item $w_{jk}^l$ - вес (weight) связи $k$-го нейрона в $(l-1)$-м слое и $j$-го нейрона в $l$-м слое.
    \item $b_j^l$ - смещение (bias) $j$-го нейрона в $l$-м слое.
    \item $a_j^l$ - активация (activation) $j$-го нейрона в $l$-м слое.
\end{itemize}

\def\layersep{3cm}
\begin{center}
    \begin{tikzpicture}[scale=1.2, transform shape, shorten >=1pt,->,draw=black!50,node distance=\layersep]
        % base neuron style: bigger, no fill, black outline
        \tikzstyle{neuron}         =[circle, draw=black, fill=none, minimum size=25pt, inner sep=0pt]
        \tikzstyle{input neuron}   =[neuron]
        \tikzstyle{hidden neuron}  =[neuron]
        \tikzstyle{output neuron}  =[neuron]
        \tikzstyle{annot}          =[text width=4em, text centered]
    
        % Input layer: 4 nodes
        \foreach \i in {1,...,4}
            \node[input neuron] (I-\i) at (0,{1.5cm-(\i-1)*1cm}) {};
    
        % Hidden layer: 5 nodes (4th labeled b_4^2)
        \foreach \i in {1,2,3,5}
            \node[hidden neuron] (H-\i) at (\layersep,{2cm-(\i-1)*1cm}) {};
        \node[hidden neuron] (H-4) at (\layersep,{2cm-(4-1)*1cm}) {$b_4^2$};
    
        % Output layer: 2 nodes (1st labeled a_1^3)
        \node[output neuron] (O-1) at (2*\layersep,{0.5cm}) {$a_1^3$};
        \node[output neuron] (O-2) at (2*\layersep,{-0.5cm}) {};
    
        % Connections: input → hidden
        \foreach \i in {1,...,4}
            \foreach \h in {1,...,5}
                \draw (I-\i) -- (H-\h);
    
        % Connections: hidden → outputs
        \foreach \h in {1,...,5}
            \foreach \o in {1,2}
                \draw (H-\h) -- (O-\o);
    
        % Special edge (H-4) → (O-1) drawn in solid black
        \draw[->,draw=black,line width=1.5pt] (H-4) -- node[midway,above,yshift=1pt] {$w_{14}^3$} (O-1);
    
        % Annotate the layers
        \node[annot,above of=H-1, node distance=1cm] (hl) {слой 2};
        \node[annot,left of=hl] {слой 1};
        \node[annot,right of=hl] {слой 3};
    \end{tikzpicture}
    
    \captionof{figure}{Схема нейронной сети с 3мя слоями и выделенными: 
    смещением $b_4^2$ (2й слой, 4й узел), выходным значением $a_1^3$ 
    (3й слой, 1й узел) и гранью, соединяющие эти два узла $w_{14}^3$.}
    \label{fig:nn_schematic}
\end{center}

Активацию мы получаем после применения функции активации $f$ к результату 
взешенной активации предыдщего слоя:
\begin{equation*}
    a_j^l \defeq f \left( \sum_k w_{jk}^l a_k^{l-1} + b_j^l \right),
\end{equation*}
где сумма происходит по всем нейронам $k$ в слое $(l-1)$. 

Также заведем еще одну переменную $z$ для взвешенной активации:
\begin{equation*}
    z_j^l \defeq \sum_k w_{jk}^l a_k^{l-1} + b_j^l.
\end{equation*}
А под $C$ будем понимать функцию стоимости.

Backprop - это про понимание того как изменение весов и смещений в сети 
влияет на изменение функции стоимости. В конечном итоге всё сводится 
к вычислению частных производных $\frac{\partial C}{\partial w_{jk}^l}$ и 
$\frac{\partial C}{\partial b_j^l}$. Но чтобы их посчитать, нам надо 
сперва ввести промежуточное значение $\delta_j^l$, которое мы будем звать 
ошибкой $j$-го нейрона в $l$-м слое. Backprop даст нам процедуру вычисления этой 
ошибки $\delta_j^l$, с помощью которой потом мы уже сможем найти 
$\frac{\partial C}{\partial w_{jk}^l}$ и $\frac{\partial C}{\partial b_j^l}$.

Определим ошибку как:
\begin{equation*}
    \delta_j^l \defeq \cfrac{\partial C}{\partial z_j^l}.
\end{equation*}
(В целом мы бы могли определить ошибку и как $\frac{\partial C}{\partial a_j^l}$. 
Вообще говоря, если так сделать, то все получится очень похоже на наши вычисления 
ниже, просто они станут немного алгебраически сложнее, так что будем использовать 
определение выше).

В основе backprop лежат 4 фундаментальных уравнения. С помощью них, мы сможем 
вычислить как ошибку $\delta_j^l$, так и градиент функции стоимости. Выведем же их 
(далее будет приведен упрощенный вывод фундаментальных уравнений, поскольку 
оригинальный вывод несколько сложнее, длинее и в конечном итоге сводится к нашему. 
Оригинальный вывод см. в \cite{backprop}).\\

\noindent\textbf{Уравнение ошибки выходного слоя, $\bm{\delta}^L$:}

Воспользовавшись правилом дифференцирования сложной функции, 
перепишем выражение для нашей ошибки в терминах частных производных 
по активациям:

\begin{equation*}
    \delta_j^L \defeq \cfrac{\partial C}{\partial z_j^L} = 
    \sum_k \cfrac{\partial C}{\partial a_k^L} \cfrac{\partial a_k^L}{\partial z_j^L}, 
\end{equation*}
где сумма происходит по всем нейронам выходного слоя. 

Вспомним, что $a_k^L \defeq f(z_k^L)$, тогда
выражение $\cfrac{\partial a_k^L}{\partial z_j^L}$ имеет смысл только когда $k=j$, 
тк при $k \neq j$, $a_k^L$ не зависит от $z_j^L$. А значит, мы можем упростить 
выражение:
\begin{equation*}
    \delta_j^L = \cfrac{\partial C}{\partial a_j^L} \cfrac{\partial a_j^L}{\partial z_j^L} 
    = \cfrac{\partial C}{\partial a_j^L} \cdot f'(z_j^L).
\end{equation*}

Это и есть наше искомое первое уравнение. Перепишем его в матричном виде:
\begin{equation}
    \bm{\delta}^L = \nabla_a C \odot f'(\bm{z}^L).
    \tag{I}
\end{equation}
Здесь и далее, $\bm{\delta}^L$ - вектор ошибок в слое $L$, 
$\nabla_a C$ - вектор, чьи компоненты это частные производные 
$\frac{\partial C}{\partial a_j^L}$, а $\odot$ означает произведение Адамара.\\

\noindent\textbf{Уравнение ошибки в терминах ошибки следующего слоя:}

Как и в прошлый раз, перепишем выражение для нашей ошибки, однако на этот раз, 
в терминах частных производных по взвешенным активациям следующего слоя:
\begin{equation*}
    \delta_j^l \defeq \cfrac{\partial C}{\partial z_j^l} = 
    \sum_k \cfrac{\partial C}{\partial z_k^{l+1}} \cfrac{\partial z_k^{l+1}}{\partial z_j^l}.
\end{equation*}
где сумма происходит по всем нейронам следующего слоя. 

Воспользовавшись нашим определением ошибки перепишем уравнение в виде:
\begin{equation}
    \delta_j^l = 
    \sum_k \cfrac{\partial C}{\partial z_k^{l+1}} \cfrac{\partial z_k^{l+1}}{\partial z_j^l} = 
    \sum_k \delta_k^{l+1} \cfrac{\partial z_k^{l+1}}{\partial z_j^l}
\end{equation}

Теперь вспомним, что $z_k^{l+1} \defeq \sum_i w_{ki}^{l+1} a_i^l + b_k^{l+1};\hspace{5pt} a_i^l \defeq f(z_i^l)$, тогда:
\begin{equation*}
    \cfrac{\partial z_k^{l+1}}{\partial z_j^l} = \sum_i w_{ki}^{l+1} \cfrac{\partial a_i^l}{\partial z_j^l},
\end{equation*}

где 
\begin{equation*}
    \cfrac{\partial a_i^l}{\partial z_j^l} = \begin{cases}
        0, \quad i \neq j \\
        f'(z_j^l), \quad i = j
    \end{cases}
\end{equation*}

Тогда
\begin{equation*}
    \cfrac{\partial z_k^{l+1}}{\partial z_j^l} = w_{kj}^{l+1} f'(z_j^l).
\end{equation*}

Подставляя в ({\color{red} todo}):
\begin{equation*}
    \delta_j^l = \sum_k \delta_k^{l+1} w_{kj}^{l+1} f'(z_j^l) = f'(z_j^l) \sum_k w_{kj}^{l+1} \delta_k^{l+1}
\end{equation*}

Это и есть наше искомое второе уравнение. Перепишем его в матричном виде:
\begin{equation*}
    \bm{\delta}^l = ((\bm{W}^{l+1})^T \bm{\delta}^{l+1}) \odot f'(z^l),
    \tag{II}
\end{equation*}
где $(\bm{W}^{l+1})^T$ означает транспонированную матрицу веса 
(элементы матрицы веса $\bm{W}^l$ слоя $l$ это веса, соединяющие с $l$-м слоем нейронов, 
т.е. элемент $j$-го ряда и $k$-го столбца нашей матрицы это $w_{jk}^l$).

Объединяя уравнения (I) и (II), мы можем вычислить ошибку $\bm{\delta}^l$ для любого 
слоя в нашей сети. Начинаем с (I) для вычисления $\bm{\delta}^L$, затем применяем 
уравнение (II) для вычисления $\bm{\delta}^{L-1}$, а затем снова уравнение (II) для 
вычисления $\bm{\delta}^{L-2}$ и так далее.\\

\noindent\textbf{Уравнение для скорости изменения функции стоимости относительно смещения:}

Опять же перепишем выражение для нашей ошибки, но в терминах частных производных 
по смещениям:
\begin{equation*}
    \delta_j^l \defeq \cfrac{\partial C}{\partial z_j^l} = 
    \cfrac{\partial C}{\partial b_j^l} \cfrac{\partial b_j^l}{\partial z_j^l}.
\end{equation*}

вспоминая, что $z_j^l \defeq \sum_k w_{jk}^l a_k^{l-1} + b_j^l$:
\begin{equation*}
    \cfrac{\partial b_j^l}{\partial z_j^l} = 
    \left( \cfrac{\partial b_j^l}{\partial z_j^l} \right)^{-1} = 1
\end{equation*}

Тогда:
\begin{equation*}
    \delta_j^l = \cfrac{\partial C}{\partial b_j^l}.
    \tag{III}
\end{equation*}

Это и есть наше искомое третье уравнение.\\

\noindent\textbf{Уравнение для скорости изменения функции стоимости относительно веса:}

Распишем что мы хотим найти:
\begin{equation}
    \cfrac{\partial C}{\partial w_{jk}^l} = \sum_m \cfrac{\partial C}{\partial z_m^l} \cfrac{\partial z_m^l}{\partial w_{jk}^l} = \cfrac{\partial C}{\partial z_j^l} \cfrac{\partial z_j^l}{\partial w_{jk}^l}
\end{equation}

Вспоминаем, что $z_j^l \defeq \sum_i w_{ji}^l a_i^{l-1} + b_j^l$, тогда:
\begin{equation*}
    \cfrac{\partial z_j^l}{\partial w_{jk}^l} = \sum_i \cfrac{\partial}{\partial w_{jk}^l} w_{ji}^l a_i^{l-1} = \begin{cases}
        a_k^{l-1}, \quad i=k \\
        0, \quad i \neq k
    \end{cases}
\end{equation*}

Подставляя в ({\color{red} todo}):
\begin{equation*}
    \cfrac{\partial C}{\partial w_{jk}^l} = a_k^{l-1} \delta_j^l.
    \tag{IV}
\end{equation*}

Таким образом мы получаем наше четвертое и последнее фундаментальное 
уравнение метода обратного распространения ошибки. 

Объединим их: \\

\begin{mdframed}[
    userdefinedwidth=0.7\textwidth,
    align=center,
    frametitle={Fundamental Backpropagation Equations},
    frametitlealignment=\centering,  % Center the title
    innertopmargin=-1em,              % Decrease space between title area and equations
    innerbottommargin=7pt,           % Space below the last equation
    innerleftmargin=10pt,            % Padding on the left of content
    innerrightmargin=10pt,           % Padding on the right of content
    frametitleaboveskip=1em,         % Space above title text (within title bar)
    frametitlebelowskip=2pt,         % Space below title text (within title bar) before content
    % Optional styling:
    % roundcorner=5pt,
    % linewidth=1pt,
    % linecolor=blue,
    % backgroundcolor=blue!10,
]
    \begin{flalign*}
        &\bm{\delta}^L = \nabla_a C \odot f'(\bm{z}^L) && \text{(I)}&\\[0.5em]
        &\bm{\delta}^l = ((\bm{W}^{l+1})^T \bm{\delta}^{l+1}) \odot f'(\bm{z}^l) && \text{(II)}&\\[0.5em]
        &\cfrac{\partial C}{\partial b_j^l} = \delta_j^l && \text{(III)}&\\[0.5em]
        &\cfrac{\partial C}{\partial w_{jk}^l} = a_k^{l-1} \delta_j^l && \text{(IV)}&
    \end{flalign*}
\end{mdframed}

Объединяя теперь с алгоритмом обучения, например стохастическим градиентным 
спуском c мини-пакетом (mini-batch) размера $m$, получим упрощенную версию 
алгоритма расчета градиента функции стоимости \cite{NN_Nielsen}:
\begin{enumerate}
    \item \textbf{Ввод набора обучающих примеров}
    \item \textbf{Для каждого обучающего примера $x$:} Установить соответствующую входную активацию $\bm{a}^{x,1}$, и выполнить следующие действия:
    \begin{itemize}
        \item \textbf{Прямое распространение:} Для каждого $l=2,3,...,L$ вычислить \\$\bm{z}^{x,l}=\bm{W}^l \bm{a}^{x,l-1} + \bm{b}^l$ и $\bm{a}^{x,l} = f(\bm{z}^{x,l})$. 
        \item \textbf{Ошибка выходного слоя $\bm{\delta}^{x,L}$:} Вычислить вектор\\ $\bm{\delta}^{x,L}=\nabla_a C_x \odot f'(\bm{z}^{x,L})$.
        \item \textbf{Обратное распространение ошибки:} Для каждого $l=L-1, L-2, ..., 2$ вычислить \\$\bm{\delta}^{x,l}=((\bm{W}^{l+1})^T \bm{\delta}^{x,l+1}) \odot f'(\bm{z}^{x,l})$.
    \end{itemize}
    \item \textbf{Градиентный спуск:} Для каждого $l=L,L-1,...,2$ обновить веса по правилу\\$\bm{W}^l \rightarrow \bm{W}^l - \frac{\eta}{m} \sum_x \bm{\delta}^{x,l} (\bm{a}^{x,l-1})^T$\\и смещения по правилу\\$\bm{b}^l \rightarrow \bm{b}^l - \frac{\eta}{m} \sum_x \bm{\delta}^{x,l}$.
\end{enumerate}

\subsection{Теоретические и практические соображения}

До сих пор мы рассматривали технические аспекты нейронных сетей, что это и как они работают. 
Однако на практике возникает ряд проблем уже непосредственно при работе с, казалось бы, готовой моделью. 
В данной главе мы затронем несколько из подобных проблем.

\subsubsection{Универсальная теорема аппроксимации}

Наверное самым интересным фактом про нейронные сети является то, что 
в теории они могут аппроксимровать почти любую функцию. Точнее, 
\textbf{универсальная теорема аппроксимации (universal approximation theorem)} 
утверждает, что сеть прямого
распространения с линейным выходным слоем и, по крайней мере, одним скрытым
слоем с произвольной «сплющивающей» функцией активации (такой, например, как
логистическая сигмоида) может аппроксимировать любую измеримую по Борелю
функцию, отображающую одно конечномерное пространство в другое с любой точ­ностью, 
при условии что в сети достаточно скрытых блоков. Универсальная теорема 
аппроксимации гласит, что какой бы ни была обучаемая
функция, найдется достаточно большой МСП, способный ее представить \cite{Goodfellow-et-al-2016}.

Однако не все так гладко. Тот факт, что \textit{существует} нейронная сеть, 
аппроксимирующая любую функцию еще не значит, что мы можем обучить, сконструировать 
или вообще распознать такую нейронную сеть.

\subsubsection{Регуляризация}

В попытках найти лучшую аппроксимацию некой функции, исследователи нередко сталкивались 
с проблемой переобучения, а значит и плохой статистической обобщаемостью модели - 
наверное, важнейшим свойством любой модели. Для решения данной проблемы, конечно, 
можно вручную наблюдать за процессом обучения и если мы видим, что модель перестала 
улучшаться, останавливать обучение. Однако у данного подхода есть две ключевые проблемы. 
Во-первых, понятие «перестала улучшаться» сугубо объективно, да и известны случаи, когда 
нейронная сеть ненадолго переставала улучшаться, прежде чем продолжить. Во-вторых сам 
факт кропотливого наблюдения за процессом обучения не эффективен.
Другим известным способом предотвращения переобучения является увеличение тренировочной 
выборки, ведь при достаточном количестве тренировочных данных, даже очень большой 
нейронной сети будет трудно переобучиться. К сожалению, тренировончные данные обычно 
трудно или дорого раздобыть.

С целью рарешения данных проблем были разработаны специальные техники уменьшения 
переобучения, известные как техники регулярязации, рассмотрим некоторые из них.

\paragraph{$L^2$-регуляризация}

Начнем с одной из наиболее часто встречающихся техник регуляризации: 
$L^2$-регуляризацией, также известной как «снижение весов» (weight decay). 
Суть данной стратегии заключается в добавлении дополнительного \textit{регуляризующего} 
члена $\Omega(\theta) = \frac{1}{2} || \bm{w} ||^2_2$ к нашей функции стоимости. 
Иногда $L^2$-регялризацию можно встретить и под другими названиями: ridge regression или 
регуляризации Тихонова.
\begin{equation*}
    C = C_0 + \lambda || \bm{w} ||^2_2,
\end{equation*}
где $C_0$ - оригинальная, нерегуляризированная функция стоимости, 
а $\lambda$ - гиперпараметр, отвечающий за «силу» регуляризации (в данной записи 
мы включили множитель $\frac{1}{2}$ в данный параметр). 

Интуитивно, суть данной регуляризации заключается в том, чтобы нейронная сеть 
предпочитала веса меньшего размера: как бы ища компромис между размером весов и 
минимизацией функции стоимости (в зависимости от параметра $\lambda$).

Однако появляется естественный вопрос, как подобный компромис поможет решить 
проблему переобучения? И строго говоря, мы не знаем. Разумеется существуют 
эвристические догадки на эту тему, но что важно: эмпирически 
было доказано, что данная и другие регуляризации работают и регуляризованные 
нейронные сети лучше обобщаются, нежели нерегуляризованные.

\paragraph{$L^1$-регуляризация}

Регуляризация по норме $L^2$ – самая распространенная форма снижения весов, но есть
и другие способы штрафовать за величину параметров модели. Одним из них является 
$L^1$-регуляризация.

Формально $L^1$-регуляризация параметров модели $w$ определяется по формуле:
\begin{equation*}
    \Omega(\theta) = ||\bm{w}||_1 = \sum_i |w_i|
\end{equation*}

т.е.:
\begin{equation*}
    C = C_0 + \lambda || \bm{w} ||_1,
\end{equation*}

Интуитивно это похоже на $L^2$ регуляризацию.

\paragraph{Dropout}

Dropout радикально отличается от $L^1$ и $L^2$ регуляризаций, вместо того, чтобы 
модифицировать функцию стоимости, он модифицирует саму нейронную сеть. 
На каждом этапе обучения мы случайно временно удаляем несколько нейронов скрытого слоя 
(где количество скрываемых нейронов - гиперпараметр), обучаем нейронную сеть как обычно 
и затем повторяем процесс, восстановив все нейроны и выбрав новые. Схематично это 
можно представить как:
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth, keepaspectratio]{dropout}
    \caption{Пример применения техники регуляризации dropout, в данном случае 
    скрывая 3 нейрона в скрытом слое.}
    \label{fig:dropout}
\end{figure}

Эвристическое объяснение данного метода есть в одной из саммых ранних работ, связанных 
с его использованием \cite{dropout}: Данная техника уменьшает сложные со-адаптации 
нейронов, тк. нейрон не может полагаться на присутствие каких-то определенных других 
нейронов. Поэтому он вынужден изучать более надежные характеристики, которые полезны 
в сочетании с множеством различных случайных подмножеств других нейронов» \cite{NN_Nielsen}.

\subsubsection{Инициализация весов}

Инициализация весов и смещений - неотъемлимая часть при работе с нейронными сетями. 
Впервые, столкнувшись с подобной задачей кажется разумными задать все параметры 
каким нибудь одним значением, допустим 0 или 1, или воспользоваться нормальным распределением, 
но не все так просто. Рассмотрим как выбор параметров из нормального распределения влияет 
на процесс обучения нейронной сети.

Допустим мы работаем с нейронной сетью с 1000ю входными нейронами, из которых 
активированы (т.е. равны 1) 500, а остальные 500 выключены (т.е. равны 0). 
Тогда, если мы брали веса из нормального распределения с математическим ожиданием равным 0 
и среднеквадратическим отклонением равным 1, наша взвешенная сумма 
$z = \sum_j w_j x_j + b$ нейрона из скрытого слоя также будет распределена, в соответствии 
с нормальным распределением с математическим ожиданием равным 0, но среднеквадратическим отклонением 
уже равным $\sqrt{501} \approx 22.4$ (500 весов и 1 смещение). Таким образом, $z$ взят из 
очень широкого нормального распределения:
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth, keepaspectratio]{N(loc=0,scale=22.4)}
    \caption{График плотности вероятности $N(\mu=0, \sigma^2=501)$.}
    \label{fig:N_scale_22.4}
\end{figure}

А значит, $|z|$ вероятнее всего будет большим. В случае сигмоидальной функции активации 
$\sigma(z)$ это будет означать, что выходное значение нейрона из скрытого слоя будет 
близко либо к 1, либо к 0. Другими словами, наш нейрон будет насыщен (saturated), а это, 
как известно, сильно замедляет процесс обучения (см. главу [1.4.4]). 

Чтобы этого избежать, рекомендуется инициализировать веса из нормального распределения со 
стандартным отклонением равным $1/\sqrt{n_\text{in}}$, где $n_\text{in}$ - количество входных 
весов. В таком случае, в рамках нашего предыдыщего примера, наша взвешенная сумма была бы 
распределена из нормального распредления с тем же нулевым математическим ожиданием, но 
уже среднеквадратическим отклонением равным $\sqrt{3/2} \approx 1.22$. Подобный нейрон с 
гораздо меньшей вероятностью будет насыщен, а значит и с меньшей вероятностью будет 
испытывать проблемы с замедлением обучения \cite{NN_Nielsen}.

\subsubsection{Проблема неустойчивого градиента}

% the vanishing gradient problem
% the exploding gradient problem
% unstable gradient problem

% https://ml.jku.at/publications/older/ch7.pdf

В случае если мы работаем с глубокими нейронными сетями, в виду особенности метода обратного 
распространения ошибки возникает проблема, известная как \textbf{проблема затухающего (или взрывающегося) 
градиента (vanishing and exploding gradient problem)}, в общем виде, \textbf{проблема неустойчивого 
градиента (unstable gradient problem)}. 

Допустим, что наш граф вычислений (построенный из операций в глубокой нейронной сети) содержит в себе 
путь, состоящий из повторных умножений на матрицу $\bm{W}$. После $t$ шагов, эта операция будет эквивалентна 
умножению на $\bm{W}^t$. Пусть спектральное разложение $\bm{W}$ имеет вид 
$\bm{W} = \bm{V} \text{diag}(\bm{\lambda}) \bm{V}^{-1}$. В этом простом случае легко увидеть, что
\begin{equation*}
    \bm{W}^t = (\bm{V}\text{diag}(\bm{\lambda})\bm{V}^{-1})^t = \bm{V}\text{diag}(\bm{\lambda})^t \bm{V}^{-1}.
\end{equation*}
Любые собственные значения $\lambda_i$, кроме близких к 1 по абсолютной величине, либо «взорвутся» (explode) 
(если их абсолютная величина больше 1), либо «затухнут» (vanish) (если абсолютная величина меньше 1). 
Проблема затухающего и взрывающегося градиента относится к тому факту, что в результате вычислений с таким графом 
градиенты масштабированы в соответствии с $\text{diag}(\bm{\lambda})^t$. В случае затухающих градиентов, трудно 
понять в каком направлении изменять параметры, чтобы улучшить функцию стоимости, а в случае взрывающихся градиентов 
обучение становится численно неустойчивым \cite{Goodfellow-et-al-2016}. 

Рассмотрим проблему неустойчивого градиента на примере следующей простой нейронной сети:

\begin{center}
    \begin{tikzpicture}[shorten >=1pt,->,draw=black,node distance=\layersep]
        % base neuron style: circle, no fill, black outline
        \tikzstyle{neuron} = [circle, draw=black, fill=none, minimum size=25pt, inner sep=0pt]
    
        % positions: input at x=0, b1 at x=\layersep, etc.
        \node[neuron]           (I)  at (0,0)          {};          % input
        \node[neuron]           (B1) at (\layersep,0)  {$b_1$};     % first hidden
        \node[neuron]           (B2) at (2*\layersep,0) {$b_2$};     % second hidden
        \node[neuron]           (B3) at (3*\layersep,0) {$b_3$};     % third hidden
        \node[neuron]           (B4) at (4*\layersep,0) {$b_4$};     % fourth hidden
        \node[] (O) at (5*\layersep,0) {$C$};       % output, label outside
    
        % connections with weight labels on the hidden‐to‐hidden edges
        \draw (I)  -- (B1);
        \draw (B1) -- node[midway,above] {$w_{2}$} (B2);
        \draw (B2) -- node[midway,above] {$w_{3}$} (B3);
        \draw (B3) -- node[midway,above] {$w_{4}$} (B4);
        \draw (B4) -- (O);
    \end{tikzpicture}

    \captionof{figure}{Схема простой нейронной сети, где 
    $w_1, w_2, ...$ - веса, $b_1, b_2, ...$ - смещения и $C$ - некая функция 
    стоимости.}
    \label{fig:nn_schematic}
\end{center}
В качестве функций активации воспользуемся сигмиодальными функциями $\sigma$.

Рассмотрим поведение градиента $\partial C/ \partial b_1$, связанного с первым 
скрытым нейроном. Воспользовавшись ранее выведенными уравнениями метода 
backpropagation, получим:
\begin{equation*}
    \cfrac{\partial C}{\partial b_1} = \sigma' (z_1) w_2 \sigma' (z_2) w_3 \sigma'(z_3) w_4 \sigma'(z_4) \cfrac{\partial C}{\partial a_4}.
\end{equation*}

За исключением последнего члена, наше выражение состоит из произведения 
членов вида $w_j \sigma' (z_j)$. Рассмотрим подробнее что это значит.

Производная нашей функции активации достигает максимума в точке $\sigma'(0) = 1/4$. 
Теперь, если мы воспользуемся стандратным подходом к инициализации весов, т.е. 
возьмем их из $N(\mu=0,\sigma=1)$, то наши веса в среднем будут удовлетворять 
неравенству $|w_j| < 1$, а значит и члены $w_j \sigma'(z_j)$ нашего 
выражения будут в среднем удовлетворять неравенству $|w_j \sigma'(z_j) < 1/4|$. 
А когда мы возьмем произвдение множества таких членов, то наше произвдение 
начнет экспоненциально уменьшаться. 

В общем виде, в нейронной сети произвольного размера, ситуация аналогична:
\begin{equation*}
    \bm{\delta}^l = \Sigma'(\bm{z}^l) (\bm{W^{l+1}})^T \Sigma' (\bm{z}^{l+1}) (\bm{W}^{l+2})^T ... \Sigma' (\bm{z}^L) \nabla_a C
\end{equation*}
Здесь, $\Sigma' (\bm{z}^l)$ - диагональная матрица, чьи элементы это значения 
$\sigma'(z)$ взвешенных входов для слоя $l$. $\bm{W}^l$ - матрицы веса для 
раличных слоев. И $\nabla_a C$ - вектор частных производных $C$ по отношению к 
выходным активациям.

Несмотря на более громоздкий вид уравнения, суть остается та же. В зависимости от 
значений матриц $\bm{W}^j$, каждый дополнительный член $(\bm{W}^j)^T \Sigma' (\bm{z}^l)$ 
либо уменьшает, либо увеличивает вектор градиента, что в результате ведет к 
проблеме затухающих и взрывающихся градиентов \cite{NN_Nielsen}.

На практике подобная проблема чаще всего встречается в 
сетях с сигмоидальными (и им подобными)
функциями активации (что и видно из наших примеров) и исторически 
является одним из самых больших препятствий на пути к успеху рекуррентных 
нейронных сетей (см. главу {\color{red}todo}).

\subsubsection{Теорема об отсутствии бесплатных завтраков}

Познакомившись с различными аспектами проектирования, 
обучения и оптимизации нейронных сетей, а также узнав про некоторые их проблемы, 
возникает естественный вопрос: разве не существует универсального алгоритма или 
модели для решения всех наших проблем? К сожалению оказывается, что нет.

\textbf{Теорема об отсутствии бесплатных завтраков (no free lunch theorem)} 
в машинном обучении \cite{NFL} утверждает, что в среднем по 
всем возможным порождающим определениям у любого алгоритма классификации 
частота ошибок классификации ранее не наблюдавшихся примеров одинакова.
Самый изощренный алгоритм, который мы только можем придумать, в среднем (по
всем возможным задачам) дает такое же качество, как простейшее предсказание: все
точки принадлежат одному классу.

По счастью, эти результаты справедливы, только если производить усреднение по
всем возможным порождающим распределениям. Если сделать предположения о видах 
распределений вероятности, встречающихся в реальных приложениях, то можно
спроектировать алгоритмы обучения, хорошо работающие для таких распределений.
Это означает, что цель работ по машинному обучению - не в том, чтобы найти
универсальный или самый лучший алгоритм обучения, а в том, чтобы понять, какие
виды распределений характерны для «реального мира», в котором функционирует
агент ИИ, и какие виды алгоритмов машинного обучения хорошо работают для интересных 
нам порождающих распределений.

Из данной теоремы вытекает, что не существует наилучшего 
алгоритма машинного обучения и, в частности, возвращаясь к вопросу переобучения, 
наилучшей формы регуляризации. 
Мы должны выбирать ту форму регуляризации, которая отвечает конкретной
решаемой задаче. Философия глубокого обучения
состоит в том, что имеется широкий круг задач (например, все интеллектуальные задачи, 
выполняемые людьми), которые можно эффективно решить, применяя весьма
универсальные формы регуляризации \cite{Goodfellow-et-al-2016}.

\subsection{Переход к RNN}

% Overall Introduction and Conclusion for this "Basics" Section: 
% Before diving into RNNs proper, have a short paragraph summarizing 
% what has been covered (NNs are powerful function approximators that 
% learn via backprop, but have limitations...) and then a clear transition 
% statement like: "However, the feed-forward architectures discussed so far 
% have inherent limitations when dealing with sequential data, such as time series. 
% They typically require fixed-size inputs and cannot maintain memory of past events. 
% To address these challenges, a different class of neural networks, Recurrent Neural 
% Networks (RNNs), was developed, which we will explore in the next section."

% \section{Рекуррентные нейронные сети}

% TODO:
% fill manifolds and topology section
% redo graphs in backprop
% show how backprop equations work on your example
% change the "big nn" figure
% Добавить в курсач в лин регрессию свободный член b
% add: why do wee need nn for predicting time series? in the introduction
% Dimensionality reduction and visualisation of high dimensional data (https://colah.github.io/posts/2014-10-Visualizing-MNIST/)
% t-SNE
% enhance listings
% split code (latex) parts into different files
% baseline model? (goodfellow)
% softmax?
